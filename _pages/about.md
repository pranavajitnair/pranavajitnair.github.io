---
layout: about
title: about
permalink: /

profile:
  align: right
  image: prof_pic.jpg
  image_circular: false # crops the image to make it circular
  more_info: >
    <p>Google DeepMind, India</p>
    <p>pranavajitnair@google.com</p>

news: true # includes a list of news items
selected_papers: true # includes a list of papers marked as "selected={true}"
social: true # includes social icons at the bottom of the page
---

I am a Pre-Doctoral Researcher working at Google DeepMind, India, with [Dr. Praneeth Netrapalli](https://praneethnetrapalli.org/), [Dr. Arun Suggala](https://www.cs.cmu.edu/~asuggala/) and [Dr. Prateek Jain](https://www.prateekjain.org/). My work involves making LLM inference faster through quantization, speculative decoding, and sparsification. I am also working on speeding up "million-context-attention" through clustering and approximate logit computation.


My interests include but are not limited to i) Making LLM inference faster through next-generation architectures, quantization, sparsification, speculative decoding, KV cache compression, adaptive routing for elastic models, etc., and ii) speeding up LLM pretraining and finetuning through better adapters, novel loss functions, better second-order optimizers and faster checkpointing.
